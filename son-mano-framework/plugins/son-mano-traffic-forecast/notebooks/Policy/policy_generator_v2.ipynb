{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Generator\n",
    "\n",
    "+ Tag the traffic trace with the version\n",
    "+ Ability to compare real vs prediction\n",
    "+ Ability to generate predictions with variable accuracies\n",
    "+ Group time periods based on Policy settings\n",
    "+ Tag each group by decided version \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yaml\n",
    "r = requests.get('https://raw.githubusercontent.com/CN-UPB/Pishahang/mvp-thesis/pish-examples/pwm-scripts/descriptors/multiversion/transcoder_mv_policy.yml')\n",
    "# print(r.text)\n",
    "PD = yaml.load(r.text, Loader=yaml.FullLoader)\n",
    "\n",
    "# PD[\"versions\"]\n",
    "\n",
    "# PD[\"versions\"] = { \n",
    "#     'virtual_deployment_units_gpu': {'transcoder-image-1-gpu': {'cost_per_min': 10,\n",
    "#    'max_data_rate': 3000,\n",
    "#    'management_overhead': 6}},\n",
    "#  'virtual_deployment_units_con': {'transcoder-image-1-con': {'cost_per_min': 3,\n",
    "#    'max_data_rate': 1200,\n",
    "#    'management_overhead': 6}}}\n",
    "\n",
    "# for _vm_type_key, _vm_type_value in PD[\"versions\"].items():\n",
    "#     print(_vm_type_key)    \n",
    "#     for _vm_version_key, _vm_version_value in _vm_type_value.items():\n",
    "#         print(_vm_version_key)\n",
    "#         print(_vm_version_value)\n",
    "#         print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Decision Steps\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "### Decision Matrix    \n",
    "\n",
    "|                    \t| Weights \t| Version1 \t| Version2 \t| Version3 \t| Score \t|\n",
    "|--------------------\t|:-------:\t|:--------:\t|:--------:\t|:--------:\t|:--------:\t|\n",
    "| Cost (-)           \t|    -4    \t|     x1   \t|    x2    \t|    x3    \t|    s    \t|\n",
    "| Over Provision (-) \t|    -3   \t|     x1   \t|    x2    \t|    x3    \t|    s    \t|\n",
    "| Overhead (-)       \t|    -4   \t|     x1   \t|    x2    \t|    x3    \t|    s    \t|\n",
    "| Support deviation (+) |    3    \t|     x1   \t|    x2    \t|    x3    \t|    s    \t|\n",
    "| Same Version (+)   \t|    3    \t|     x1   \t|    x2    \t|    x3    \t|    s    \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "_SCORE_MIN, _SCORE_MAX = 1, 5\n",
    "\n",
    "'''\n",
    "Find the version with the max supported datarate\n",
    "'''\n",
    "def find_max_datarate_version(versions):\n",
    "    _max_datarate = 0\n",
    "\n",
    "    for _vm_type_key, _vm_type_value in versions.items():\n",
    "        # print(_vm_type_key)    \n",
    "\n",
    "        for _vm_version_key, _vm_version_value in _vm_type_value.items():\n",
    "            # print(_vm_version_key)\n",
    "            # print(_vm_version_value[\"max_data_rate\"])\n",
    "\n",
    "            if _vm_version_value[\"max_data_rate\"] > _max_datarate:\n",
    "                _max_datarate = _vm_version_value[\"max_data_rate\"]\n",
    "                _max_datarate_version = { _vm_type_key: { _vm_version_key : _vm_version_value } }\n",
    "\n",
    "    return _max_datarate_version\n",
    "\n",
    "'''\n",
    "Get all the versions that can support the datarate demand\n",
    "'''\n",
    "def get_supported_versions(prediction, versions):\n",
    "    # Iterate versions\n",
    "    datarate_supported_versions = {}\n",
    "\n",
    "    for _vm_type_key, _vm_type_value in versions.items():\n",
    "        # print(_vm_type_key)    \n",
    "\n",
    "        for _vm_version_key, _vm_version_value in _vm_type_value.items():\n",
    "            # print(_vm_version_key)\n",
    "            # print(_vm_version_value[\"max_data_rate\"])\n",
    "            # print(prediction[\"mean\"])\n",
    "            if _vm_version_value[\"max_data_rate\"] >= prediction[\"mean\"]:\n",
    "                # check if key present else add\n",
    "                if _vm_type_key in datarate_supported_versions:\n",
    "                    datarate_supported_versions[_vm_type_key][_vm_version_key] = _vm_version_value\n",
    "                else:\n",
    "                    datarate_supported_versions[_vm_type_key] = {}\n",
    "                    datarate_supported_versions[_vm_type_key][_vm_version_key] = _vm_version_value\n",
    "\n",
    "    if len(datarate_supported_versions) == 0:\n",
    "        return find_max_datarate_version(versions)\n",
    "    return datarate_supported_versions\n",
    "\n",
    "'''\n",
    "Interpolate data points to a certain range\n",
    "'''\n",
    "def interpolate_array(values, min=_SCORE_MIN, max=_SCORE_MAX):\n",
    "    return np.interp(values, (values.min(), values.max()), (min, max))\n",
    "\n",
    "\n",
    "'''\n",
    "Build the decision matrix for a given traffic prediction values \n",
    "'''\n",
    "def build_decision_matrix(prediction, meta, versions):\n",
    "    _decision_matrix = {}\n",
    "    for _vm_type_key, _vm_type_value in versions.items():\n",
    "        for _vm_version_key, _vm_version_value in _vm_type_value.items():\n",
    "                if _vm_type_key not in _decision_matrix:\n",
    "                    _decision_matrix[_vm_type_key] = {}\n",
    "                if _vm_version_key not in _decision_matrix[_vm_type_key]:\n",
    "                    _decision_matrix[_vm_type_key][_vm_version_key] = {}\n",
    "\n",
    "                # Cost\n",
    "                _decision_matrix[_vm_type_key][_vm_version_key][\"cost\"] = _vm_version_value['cost_per_min']\n",
    "\n",
    "                # Support deviation\n",
    "                if _vm_version_value['max_data_rate'] > (prediction['mean'] + prediction['std']):\n",
    "                    _decision_matrix[_vm_type_key][_vm_version_key][\"support_deviation\"] = 5\n",
    "                else:\n",
    "                    _decision_matrix[_vm_type_key][_vm_version_key][\"support_deviation\"] = 1\n",
    "\n",
    "                # Over Provision\n",
    "                _decision_matrix[_vm_type_key][_vm_version_key][\"over_provision\"] = int(_vm_version_value['max_data_rate']) - int(prediction['mean'])\n",
    "\n",
    "                # Same Version\n",
    "                if meta[\"current_version\"] == _vm_version_key:\n",
    "                    _decision_matrix[_vm_type_key][_vm_version_key][\"same_version\"] = 5\n",
    "                else:\n",
    "                    _decision_matrix[_vm_type_key][_vm_version_key][\"same_version\"] = 1\n",
    "\n",
    "                # Overhead\n",
    "                _decision_matrix[_vm_type_key][_vm_version_key][\"overhead\"] = _vm_version_value['management_overhead']\n",
    "\n",
    "                # Support max datarate\n",
    "                if _vm_version_value['max_data_rate'] >= (prediction['max']):\n",
    "                    _decision_matrix[_vm_type_key][_vm_version_key][\"support_max\"] = 5\n",
    "                else:\n",
    "                    _decision_matrix[_vm_type_key][_vm_version_key][\"support_max\"] = 1\n",
    "\n",
    "                # Support recent history\n",
    "                if _vm_version_value['max_data_rate'] >= (meta[\"recent_history\"][\"mean\"]):\n",
    "                    _decision_matrix[_vm_type_key][_vm_version_key][\"support_recent_history\"] = 5\n",
    "                else:\n",
    "                    _decision_matrix[_vm_type_key][_vm_version_key][\"support_recent_history\"] = 1\n",
    "\n",
    "\n",
    "    decision_matrix_df = pd.DataFrame.from_dict({(i,j): _decision_matrix[i][j] \n",
    "                                for i in _decision_matrix.keys() \n",
    "                                for j in _decision_matrix[i].keys()},\n",
    "                                orient='index')\n",
    "\n",
    "    decision_matrix_df[\"over_provision\"] = interpolate_array(decision_matrix_df[\"over_provision\"])\n",
    "    decision_matrix_df[\"cost\"] = interpolate_array(decision_matrix_df[\"cost\"])\n",
    "    decision_matrix_df[\"overhead\"] = interpolate_array(decision_matrix_df[\"overhead\"])\n",
    "\n",
    "    return decision_matrix_df\n",
    "\n",
    "'''\n",
    "Get policy decision given decision matrix and weights\n",
    "'''\n",
    "def get_policy_decision(decision_matrix, weights):\n",
    "\n",
    "    # Negative\n",
    "    cost = -1 * weights[\"negative\"][\"cost\"]\n",
    "    over_provision = -1 * weights[\"negative\"][\"over_provision\"]\n",
    "    overhead = -1 * weights[\"negative\"][\"overhead\"]\n",
    "\n",
    "    # Positive\n",
    "    support_deviation = weights[\"positive\"]['support_deviation']\n",
    "    same_version = weights[\"positive\"]['same_version']\n",
    "\n",
    "    # WEIGHTS --> [cost, over_provision, overhead, support_deviation, same_version]\n",
    "    weights_row = [cost, over_provision, overhead, support_deviation, same_version]\n",
    "\n",
    "    for index_label, row_series in decision_matrix.iterrows():\n",
    "        _row = np.array([row_series.cost, row_series.over_provision, row_series.overhead, row_series.support_deviation, row_series.same_version])\n",
    "\n",
    "        decision_matrix.at[index_label , 'score'] = np.dot(np.array(weights_row), _row)\n",
    "\n",
    "    _version = decision_matrix[decision_matrix.score == decision_matrix.score.max()].index[0]\n",
    "    return _version\n",
    "\n",
    "'''\n",
    "Find the version with least cost\n",
    "'''\n",
    "def find_cheapest_version(versions):\n",
    "    _cost = None\n",
    "\n",
    "    for _vm_type_key, _vm_type_value in versions.items():\n",
    "        # print(_vm_type_key)    \n",
    "\n",
    "        for _vm_version_key, _vm_version_value in _vm_type_value.items():\n",
    "            # print(_vm_version_key)\n",
    "            # print(_vm_version_value[\"max_data_rate\"])\n",
    "            # FIXME: cost_per_min should be int\n",
    "            if _cost is None:\n",
    "                _cost = _vm_version_value[\"cost_per_min\"]\n",
    "                _cost_version = (_vm_type_key, _vm_version_key )\n",
    "\n",
    "            if int(_vm_version_value[\"cost_per_min\"]) < int(_cost):\n",
    "                _cost = _vm_version_value[\"cost_per_min\"]\n",
    "                # _cost_version = { _vm_type_key: { _vm_version_key : _vm_version_value } }\n",
    "                _cost_version = (_vm_type_key, _vm_version_key )\n",
    "\n",
    "    return _cost_version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Policy on Dataset\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(11000, 1)\n(2200, 4)\n(11000, 1)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          sent\n0  1143.842358\n1  1181.595847\n2  1158.080520\n3  1189.863609\n4  1190.384826",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1143.842358</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1181.595847</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1158.080520</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1189.863609</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1190.384826</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LOOK_AHEAD = 5 # Mins\n",
    "\n",
    "traffic_training_complete = pd.read_csv(r'/plugins/son-mano-traffic-forecast/notebooks/data/dataset_six_traffic.csv', index_col=0)\n",
    "print(traffic_training_complete.shape)\n",
    "traffic_training_complete.head(5)\n",
    "\n",
    "# traffic_training_complete = traffic_training_complete[:720]\n",
    "\n",
    "traffic_grouped = traffic_training_complete.groupby(\n",
    "                    np.arange(len(traffic_training_complete))//LOOK_AHEAD).agg(['mean', 'std', 'min', 'max'])\n",
    "\n",
    "traffic_history = traffic_training_complete.reset_index().copy().drop('index', axis=1)\n",
    "\n",
    "# traffic_history = traffic_history[:1440] \n",
    "# result.index = df.loc[1::2, 'Idx']\n",
    "print(traffic_grouped.shape)\n",
    "print(traffic_history.shape)\n",
    "\n",
    "traffic_history.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Run Policy on Dataset\n",
    "# WEIGHTS --> [cost, over_provision, overhead, support_deviation, same_version]\n",
    "WEIGHTS = {\n",
    "    \"negative\": {\n",
    "      \"cost\": 5,\n",
    "      \"over_provision\": 2,\n",
    "      \"overhead\": 3\n",
    "    },\n",
    "    \"positive\": {\n",
    "      \"support_deviation\": 1,\n",
    "      \"same_version\": 1,\n",
    "      \"support_max\": 1,\n",
    "      \"support_recent_history\": 1\n",
    "    }\n",
    "  }\n",
    "\n",
    "prediction = { \"mean\": 400, \"std\": 100, \"min\": 800, \"max\": 1800 }\n",
    "\n",
    "traffic_policy_test = traffic_grouped['sent'].copy()\n",
    "# traffic_policy_test.plot()\n",
    "\n",
    "# iterate over the dataframe row by row and set version\n",
    "meta = { \n",
    "   \"current_version\": \"transcoder-image-1-vm\",\n",
    "   \"current_version_history\": \"transcoder-image-1-vm\",\n",
    "   \"recent_history\": None\n",
    "}\n",
    "\n",
    "switch_counter = {\n",
    "   \"history\": 0,\n",
    "   \"policy\": 0,\n",
    "   \"notsame\": 0\n",
    "}\n",
    "\n",
    "with open(\"output_debug.log\", \"w\") as f:\n",
    "   for index_label, row_series in traffic_policy_test.iterrows():\n",
    "      if meta[\"recent_history\"] is None:\n",
    "         meta[\"recent_history\"] = row_series\n",
    "\n",
    "      supported_versions = get_supported_versions(prediction=row_series, versions=PD[\"versions\"])\n",
    "\n",
    "      decision_matrix_df = build_decision_matrix(prediction=row_series, meta=meta, versions=supported_versions)\n",
    "\n",
    "      _selected_version = \":\".join(get_policy_decision(decision_matrix_df, WEIGHTS))\n",
    "      traffic_policy_test.at[index_label , 'policy'] = _selected_version\n",
    "      \n",
    "      if not _selected_version.split(\":\")[1] == meta[\"current_version\"]:\n",
    "         switch_counter[\"policy\"] += 1\n",
    "\n",
    "      f.write(\"\\nrecent_history\\n\")\n",
    "      f.write(str(meta[\"recent_history\"]))\n",
    "      f.write(\"\\nForecast\\n\")\n",
    "      f.write(str(row_series))\n",
    "\n",
    "      meta = {\n",
    "         \"current_version\": _selected_version.split(\":\")[1],\n",
    "         \"recent_history\": row_series\n",
    "      } \n",
    "\n",
    "\n",
    "      f.write(\"\\n\\n_selected_version\\n\")\n",
    "      f.write(_selected_version)\n",
    "      \n",
    "      f.write(\"\\n\\n\")\n",
    "      f.write(str(decision_matrix_df))\n",
    "      f.write(\"\\n\\n\")\n",
    "      # print(row_series)\n",
    "      # print(decision_matrix_df)\n",
    "      # print(\"\\n\\n\")\n",
    "   \n",
    "# print(switch_counter)\n",
    "# traffic_policy_test.to_csv('./data/{}m_policy_decisions_dataset_six_traffic.csv'.format(LOOK_AHEAD))\n",
    "# traffic_policy_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = { \n",
    "   \"current_version_history\": \"transcoder-image-1-vm\",\n",
    "   \"recent_history\": None\n",
    "}\n",
    "\n",
    "row_counter = 0\n",
    "\n",
    "for index_label, row_series in traffic_history.iterrows():\n",
    "   if meta[\"recent_history\"] is None:\n",
    "      meta[\"recent_history\"] = row_series['sent']\n",
    "\n",
    "   supported_versions_history = get_supported_versions(prediction={\"mean\": meta['recent_history']}, versions=PD[\"versions\"])\n",
    "\n",
    "   _selected_version_history = \":\".join(find_cheapest_version(versions=supported_versions_history))\n",
    "   traffic_history.at[index_label , 'history'] = _selected_version_history\n",
    "\n",
    "   if not _selected_version_history.split(\":\")[1] == meta[\"current_version_history\"]:\n",
    "      switch_counter[\"history\"] += 1\n",
    "\n",
    "   meta = {\n",
    "      \"current_version_history\": _selected_version_history.split(\":\")[1],\n",
    "      \"recent_history\": row_series['sent']\n",
    "   } \n",
    "\n",
    "   row_counter += 1\n",
    "\n",
    "# print(switch_counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Switch Stats\n{'history': 625, 'policy': 45, 'notsame': 0}\n\nPolicy\nvirtual_deployment_units_con:transcoder-image-1-con    6350\nvirtual_deployment_units_gpu:transcoder-image-1-gpu    4650\nName: policy, dtype: int64\n\nHistory\nvirtual_deployment_units_gpu:transcoder-image-1-gpu    4595\nvirtual_deployment_units_con:transcoder-image-1-con    3692\nvirtual_deployment_units_vm:transcoder-image-1-vm      2713\nName: history, dtype: int64\n(11000, 6)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          mean        std          min          max  \\\n0  1172.753432  20.814400  1143.842358  1190.384826   \n1  1172.753432  20.814400  1143.842358  1190.384826   \n2  1172.753432  20.814400  1143.842358  1190.384826   \n3  1172.753432  20.814400  1143.842358  1190.384826   \n4  1172.753432  20.814400  1143.842358  1190.384826   \n5  1218.337667   8.049923  1210.799511  1230.664978   \n6  1218.337667   8.049923  1210.799511  1230.664978   \n7  1218.337667   8.049923  1210.799511  1230.664978   \n8  1218.337667   8.049923  1210.799511  1230.664978   \n9  1218.337667   8.049923  1210.799511  1230.664978   \n\n                                              policy  \\\n0  virtual_deployment_units_con:transcoder-image-...   \n1  virtual_deployment_units_con:transcoder-image-...   \n2  virtual_deployment_units_con:transcoder-image-...   \n3  virtual_deployment_units_con:transcoder-image-...   \n4  virtual_deployment_units_con:transcoder-image-...   \n5  virtual_deployment_units_gpu:transcoder-image-...   \n6  virtual_deployment_units_gpu:transcoder-image-...   \n7  virtual_deployment_units_gpu:transcoder-image-...   \n8  virtual_deployment_units_gpu:transcoder-image-...   \n9  virtual_deployment_units_gpu:transcoder-image-...   \n\n                                             history  \n0  virtual_deployment_units_con:transcoder-image-...  \n1  virtual_deployment_units_con:transcoder-image-...  \n2  virtual_deployment_units_con:transcoder-image-...  \n3  virtual_deployment_units_con:transcoder-image-...  \n4  virtual_deployment_units_con:transcoder-image-...  \n5  virtual_deployment_units_con:transcoder-image-...  \n6  virtual_deployment_units_gpu:transcoder-image-...  \n7  virtual_deployment_units_gpu:transcoder-image-...  \n8  virtual_deployment_units_gpu:transcoder-image-...  \n9  virtual_deployment_units_gpu:transcoder-image-...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>policy</th>\n      <th>history</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1172.753432</td>\n      <td>20.814400</td>\n      <td>1143.842358</td>\n      <td>1190.384826</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1172.753432</td>\n      <td>20.814400</td>\n      <td>1143.842358</td>\n      <td>1190.384826</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1172.753432</td>\n      <td>20.814400</td>\n      <td>1143.842358</td>\n      <td>1190.384826</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1172.753432</td>\n      <td>20.814400</td>\n      <td>1143.842358</td>\n      <td>1190.384826</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1172.753432</td>\n      <td>20.814400</td>\n      <td>1143.842358</td>\n      <td>1190.384826</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1218.337667</td>\n      <td>8.049923</td>\n      <td>1210.799511</td>\n      <td>1230.664978</td>\n      <td>virtual_deployment_units_gpu:transcoder-image-...</td>\n      <td>virtual_deployment_units_con:transcoder-image-...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1218.337667</td>\n      <td>8.049923</td>\n      <td>1210.799511</td>\n      <td>1230.664978</td>\n      <td>virtual_deployment_units_gpu:transcoder-image-...</td>\n      <td>virtual_deployment_units_gpu:transcoder-image-...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1218.337667</td>\n      <td>8.049923</td>\n      <td>1210.799511</td>\n      <td>1230.664978</td>\n      <td>virtual_deployment_units_gpu:transcoder-image-...</td>\n      <td>virtual_deployment_units_gpu:transcoder-image-...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1218.337667</td>\n      <td>8.049923</td>\n      <td>1210.799511</td>\n      <td>1230.664978</td>\n      <td>virtual_deployment_units_gpu:transcoder-image-...</td>\n      <td>virtual_deployment_units_gpu:transcoder-image-...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1218.337667</td>\n      <td>8.049923</td>\n      <td>1210.799511</td>\n      <td>1230.664978</td>\n      <td>virtual_deployment_units_gpu:transcoder-image-...</td>\n      <td>virtual_deployment_units_gpu:transcoder-image-...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# pd.concat([traffic_policy_test]*2, ignore_index=True)\n",
    "final_decision_dataset = traffic_policy_test.iloc[np.repeat(np.arange(len(traffic_policy_test)), 5)].reset_index().drop('index', axis=1)\n",
    "final_decision_dataset['history'] = traffic_history['history']\n",
    "\n",
    "print(\"Switch Stats\")\n",
    "print(switch_counter)\n",
    "\n",
    "print(\"\\nPolicy\")\n",
    "print(final_decision_dataset['policy'].value_counts())\n",
    "\n",
    "print(\"\\nHistory\")\n",
    "print(final_decision_dataset['history'].value_counts())\n",
    "\n",
    "final_decision_dataset.to_csv('./data/{}m_policy_decisions_dataset_six_traffic.csv'.format(LOOK_AHEAD))\n",
    "print(final_decision_dataset.shape)\n",
    "final_decision_dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/53766397/how-to-center-the-grid-of-a-plot-on-scatter-points\n",
    "# https://stackoverflow.com/questions/47684652/how-to-customize-marker-colors-and-shapes-in-scatter-plot\n",
    "DRAW_SCATTER = False\n",
    "if DRAW_SCATTER:\n",
    "    from matplotlib import pyplot as plt \n",
    "\n",
    "    markers = [\"s\" , \"s\" , \"o\" , \"v\" , \"^\" , \"<\", \">\"]\n",
    "    colors = ['r','g','b','c','m', 'y', 'k']\n",
    "\n",
    "    x = final_decision_dataset.index\n",
    "    y = [final_decision_dataset.policy, final_decision_dataset.history]\n",
    "    labels = ['policy', 'history']\n",
    "\n",
    "    # traffic_policy_test.reset_index().plot.scatter(figsize=(20,10), fontsize=20, x=x, y=y, marker=\"v\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(200,2))\n",
    "    for i in range(2): #for each of the 7 features \n",
    "        mi = markers[i] #marker for ith feature \n",
    "        xi = x #x array for ith feature .. here is where you would generalize      different x for every feature\n",
    "        yi = y[i] #y array for ith feature \n",
    "        ci = colors[i] #color for ith feature \n",
    "        ax.scatter(xi,yi, marker=mi, color=ci, s=49, label=labels[i])\n",
    "\n",
    "    ax.set_yticks(np.arange(3))\n",
    "    ax.set_yticks(np.arange(3+1)-0.5, minor=True)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(y[0])))\n",
    "    ax.set_xticks(np.arange(len(y[0])+1)-0.5, minor=True)\n",
    "\n",
    "    ax.grid(True, which=\"minor\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}